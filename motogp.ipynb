import pandas as pd
import numpy as np
import lightgbm as lgb
from lightgbm import LGBMRegressor, early_stopping, log_evaluation
from sklearn.preprocessing import OrdinalEncoder
from sklearn.metrics import mean_squared_error, r2_score
import warnings
warnings.filterwarnings("ignore")

# Load data
train = pd.read_csv("train.csv", encoding='latin1', engine='python', on_bad_lines='skip')
val = pd.read_csv("val.csv", encoding='latin1', engine='python', on_bad_lines='skip')
test = pd.read_csv("test.csv", encoding='latin1', engine='python', on_bad_lines='skip')
sample_submission = pd.read_csv("sample_submission.csv")

# Define target column
target = 'Lap_Time_Seconds'

# Fix target dtype in case it was read as object
train[target] = pd.to_numeric(train[target], errors='coerce')
val[target] = pd.to_numeric(val[target], errors='coerce')

# Drop rows with NaN in target
train.dropna(subset=[target], inplace=True)
val.dropna(subset=[target], inplace=True)

# Extract target
train_y = train[target]
val_y = val[target]

# Identify common features
features = [col for col in train.columns if col != target and col in val.columns and col in test.columns]

# Prepare X sets
train_X = train[features].copy()
val_X = val[features].copy()
test_X = test[features].copy()

# Identify categorical and numeric columns
categorical_cols = train_X.select_dtypes(include='object').columns.tolist()
numeric_cols = train_X.select_dtypes(include=np.number).columns.tolist()

# Fill missing values
for col in numeric_cols:
    median = train_X[col].median()
    train_X[col].fillna(median, inplace=True)
    val_X[col].fillna(median, inplace=True)
    test_X[col].fillna(median, inplace=True)

for col in categorical_cols:
    train_X[col].fillna('Unknown', inplace=True)
    val_X[col].fillna('Unknown', inplace=True)
    test_X[col].fillna('Unknown', inplace=True)

# Feature Engineering - Rider_Bike combo
if 'Rider' in train_X.columns and 'Bike' in train_X.columns:
    train_X['Rider_Bike'] = train_X['Rider'] + '_' + train_X['Bike']
    val_X['Rider_Bike'] = val_X['Rider'] + '_' + val_X['Bike']
    test_X['Rider_Bike'] = test_X['Rider'] + '_' + test_X['Bike']
    categorical_cols.append('Rider_Bike')

# Rider average lap time
if 'Rider' in train_X.columns:
    rider_mean = train.groupby('Rider')[target].mean().to_dict()
    train_X['Rider_Avg_Lap'] = train_X['Rider'].map(rider_mean)
    val_X['Rider_Avg_Lap'] = val_X['Rider'].map(rider_mean)
    test_X['Rider_Avg_Lap'] = test_X['Rider'].map(rider_mean)
    numeric_cols.append('Rider_Avg_Lap')

# Ordinal encode categoricals
encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)
train_X[categorical_cols] = encoder.fit_transform(train_X[categorical_cols].astype(str))
val_X[categorical_cols] = encoder.transform(val_X[categorical_cols].astype(str))
test_X[categorical_cols] = encoder.transform(test_X[categorical_cols].astype(str))

# Initialize LightGBM model
model = LGBMRegressor(
    objective='regression',
    learning_rate=0.05,
    n_estimators=1000,
    num_leaves=64,
    feature_fraction=0.85,
    bagging_fraction=0.85,
    bagging_freq=5,
    random_state=42
)

# Train with early stopping via callbacks
model.fit(
    train_X, train_y,
    eval_set=[(val_X, val_y)],
    eval_metric='rmse',
    callbacks=[early_stopping(50), log_evaluation(100)],
    categorical_feature=categorical_cols
)

# Validation predictions
val_preds = model.predict(val_X)
rmse = np.sqrt(mean_squared_error(val_y, val_preds))
r2 = r2_score(val_y, val_preds)

print(f"‚úÖ RMSE on Validation Set: {rmse:.4f}")
print(f"‚úÖ R¬≤ Score on Validation Set: {r2:.4f}")

# Test predictions
test_preds = model.predict(test_X)
sample_submission['Lap_Time_Seconds'] = test_preds
sample_submission.to_csv("submission.csv", index=False)
print("üìÅ submission.csv saved!")
